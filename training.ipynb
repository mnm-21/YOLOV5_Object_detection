{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-10T06:12:45.928501Z","iopub.execute_input":"2024-01-10T06:12:45.929144Z","iopub.status.idle":"2024-01-10T06:12:45.938274Z","shell.execute_reply.started":"2024-01-10T06:12:45.929116Z","shell.execute_reply":"2024-01-10T06:12:45.937324Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-01-10T06:12:45.939816Z","iopub.execute_input":"2024-01-10T06:12:45.940141Z","iopub.status.idle":"2024-01-10T06:12:46.885857Z","shell.execute_reply.started":"2024-01-10T06:12:45.940103Z","shell.execute_reply":"2024-01-10T06:12:46.884729Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#!git clone https://github.com/ultralytics/yolov5 ","metadata":{"execution":{"iopub.status.busy":"2024-01-10T06:12:46.887305Z","iopub.execute_input":"2024-01-10T06:12:46.887570Z","iopub.status.idle":"2024-01-10T06:12:49.646418Z","shell.execute_reply.started":"2024-01-10T06:12:46.887546Z","shell.execute_reply":"2024-01-10T06:12:49.645346Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'yolov5'...\nremote: Enumerating objects: 16260, done.\u001b[K\nremote: Counting objects: 100% (157/157), done.\u001b[K\nremote: Compressing objects: 100% (131/131), done.\u001b[K\nremote: Total 16260 (delta 66), reused 73 (delta 26), pack-reused 16103\u001b[K\nReceiving objects: 100% (16260/16260), 15.06 MiB | 20.54 MiB/s, done.\nResolving deltas: 100% (11097/11097), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd yolov5","metadata":{"execution":{"iopub.status.busy":"2024-01-10T06:12:49.649206Z","iopub.execute_input":"2024-01-10T06:12:49.650147Z","iopub.status.idle":"2024-01-10T06:12:49.659520Z","shell.execute_reply.started":"2024-01-10T06:12:49.650116Z","shell.execute_reply":"2024-01-10T06:12:49.658482Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/yolov5\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-01-10T06:12:49.661136Z","iopub.execute_input":"2024-01-10T06:12:49.661750Z","iopub.status.idle":"2024-01-10T06:12:50.618859Z","shell.execute_reply.started":"2024-01-10T06:12:49.661725Z","shell.execute_reply":"2024-01-10T06:12:50.617661Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"CITATION.cff\t README.zh-CN.md  detect.py   pyproject.toml\ttutorial.ipynb\nCONTRIBUTING.md  benchmarks.py\t  export.py   requirements.txt\tutils\nLICENSE\t\t classify\t  hubconf.py  segment\t\tval.py\nREADME.md\t data\t\t  models      train.py\n","output_type":"stream"}]},{"cell_type":"code","source":"%pip install -qr requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-01-10T06:12:50.620474Z","iopub.execute_input":"2024-01-10T06:12:50.620849Z","iopub.status.idle":"2024-01-10T06:13:04.639101Z","shell.execute_reply.started":"2024-01-10T06:12:50.620814Z","shell.execute_reply":"2024-01-10T06:13:04.637738Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\nimport os\n\n# Create the train_test_data folder in /kaggle/working/yolov5 if it doesn't exist\ntrain_test_data_path = '/kaggle/working/yolov5/train_test_data'\nif not os.path.exists(train_test_data_path):\n    os.mkdir(train_test_data_path)\n\n# Copy the voc2012-processed-data-for-yolov5 folder into train_test_data\nshutil.copytree('/kaggle/input/voc2012-processed-data-for-yolov5', train_test_data_path, dirs_exist_ok=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T06:52:49.735497Z","iopub.execute_input":"2024-01-10T06:52:49.735854Z","iopub.status.idle":"2024-01-10T06:53:41.448144Z","shell.execute_reply.started":"2024-01-10T06:52:49.735825Z","shell.execute_reply":"2024-01-10T06:53:41.447136Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/yolov5/train_test_data'"},"metadata":{}}]},{"cell_type":"code","source":"with open(\"/kaggle/working/yolov5/data2.yaml\", \"w+\") as file_:\n    file_.write(\n        \"\"\"\n        \n        train: \n          - /kaggle/working/yolov5/train_test_data/train/train/SplitFolder5\n          - /kaggle/working/yolov5/train_test_data/train/train/SplitFolder4\n        val: /kaggle/working/yolov5/train_test_data/test/test\n        nc: 20\n        names: ['person',\n                'car',\n                'chair',\n                'bottle',\n                'pottedplant',\n                'bird',\n                'dog',\n                'sofa',\n                'bicycle',\n                'horse',\n                'boat',\n                'motorbike',\n                'cat',\n                'tvmonitor',\n                'cow',\n                'sheep',\n                'aeroplane',\n                'train',\n                'diningtable',\n                'bus'\n                ]\n        \n        \"\"\"\n    )\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T07:52:27.467585Z","iopub.execute_input":"2024-01-10T07:52:27.468330Z","iopub.status.idle":"2024-01-10T07:52:27.473841Z","shell.execute_reply.started":"2024-01-10T07:52:27.468297Z","shell.execute_reply":"2024-01-10T07:52:27.472857Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"!python train.py --data data2.yaml --cfg yolov5s.yaml --batch-size 10 --name Model --epochs 50","metadata":{"execution":{"iopub.status.busy":"2024-01-10T07:52:45.385751Z","iopub.execute_input":"2024-01-10T07:52:45.386387Z","iopub.status.idle":"2024-01-10T09:55:24.372857Z","shell.execute_reply.started":"2024-01-10T07:52:45.386355Z","shell.execute_reply":"2024-01-10T09:55:24.371659Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=data2.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=10, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=Model, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['Pillow>=10.0.1'] not found, attempting AutoUpdate...\nRequirement already satisfied: Pillow>=10.0.1 in /opt/conda/lib/python3.10/site-packages (10.1.0)\n\n\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 11.2s, installed 1 package: ['Pillow>=10.0.1']\n\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n\nYOLOv5 üöÄ v7.0-270-g4733b4d Python-3.10.12 torch-2.0.0 CUDA:0 (Tesla T4, 15102MiB)\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\nOverriding model.yaml nc=80 with nc=20\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n 24      [17, 20, 23]  1     67425  models.yolo.Detect                      [20, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\nYOLOv5s summary: 214 layers, 7073569 parameters, 7073569 gradients, 16.1 GFLOPs\n\nTransferred 342/349 items from yolov5s.pt\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.00046875), 60 bias\nWARNING ‚ö†Ô∏è DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\nSee Multi-GPU Tutorial at https://docs.ultralytics.com/yolov5/tutorials/multi_gpu_training to get started.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolov5/train_test_data/train/train/SplitFolder4.\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/yolov5/train_test_data/train/train/SplitFolder4.cache\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolov5/train_test_data/test/test.cache... 3425 ima\u001b[0m\n\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.91 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\nPlotting labels to runs/train/Model/labels.jpg... \n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/train/Model\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       0/49      1.27G    0.06896    0.03295    0.04604         46        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.444      0.145      0.162     0.0814\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       1/49      2.85G    0.04951    0.02809    0.02626         38        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914       0.43       0.36      0.337      0.175\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       2/49      2.85G     0.0491    0.02867    0.02264         42        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.355      0.355      0.284      0.134\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       3/49      2.85G     0.0479    0.03068    0.02368         35        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.334      0.313      0.244      0.115\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       4/49      2.85G    0.04795     0.0313     0.0232         39        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.338      0.326      0.251      0.114\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       5/49      2.85G    0.04643    0.03093    0.02139         35        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.385       0.33      0.281      0.129\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       6/49      2.85G    0.04562    0.03071    0.02066         31        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.401      0.334      0.287      0.127\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       7/49      2.85G    0.04409    0.03025    0.01983         38        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.408       0.34      0.294       0.14\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       8/49      2.85G    0.04372    0.03018    0.01931         39        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.476      0.356      0.349      0.169\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       9/49      2.85G    0.04269     0.0303    0.01802         35        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.451      0.382      0.368      0.179\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      10/49      2.85G     0.0418    0.02957    0.01622         55        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.469      0.396       0.38      0.188\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      11/49      2.85G    0.04161    0.02965    0.01606         55        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.422      0.382      0.358      0.175\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      12/49      2.85G    0.04054    0.02938    0.01595         37        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.412      0.385      0.339      0.171\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      13/49      2.85G    0.04008    0.02868    0.01546         34        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.504      0.411      0.393      0.196\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      14/49      2.85G    0.03964    0.02898    0.01439         35        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914        0.5      0.396      0.399      0.205\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      15/49      2.85G     0.0389    0.02826    0.01405         57        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.466      0.431      0.415      0.214\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      16/49      2.85G    0.03898    0.02825    0.01347         60        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914       0.48      0.403      0.396      0.206\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      17/49      2.85G    0.03849    0.02804    0.01335         32        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.514      0.416      0.414      0.219\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      18/49      2.85G    0.03764    0.02792    0.01255         22        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.483       0.42      0.393      0.208\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      19/49      2.85G    0.03686    0.02725    0.01177         29        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.531       0.44      0.442      0.234\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      20/49      2.85G    0.03714     0.0275    0.01209         50        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914       0.51      0.426      0.424      0.223\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      21/49      2.85G    0.03685    0.02753    0.01124         37        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.514      0.453      0.438      0.242\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      22/49      2.85G    0.03619    0.02727    0.01107         34        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.547      0.447      0.447      0.247\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      23/49      2.85G    0.03611    0.02716     0.0107         43        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.568      0.451      0.465      0.256\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      24/49      2.85G    0.03511     0.0266   0.009969         37        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.573      0.448      0.466      0.257\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      25/49      2.85G    0.03502    0.02685    0.01025         34        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.541      0.455      0.464      0.262\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      26/49      2.85G    0.03488    0.02632   0.009931         36        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.549      0.463      0.474      0.263\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      27/49      2.85G    0.03403    0.02585   0.009515         46        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.551      0.461      0.474      0.265\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      28/49      2.85G    0.03366    0.02603   0.009425         34        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.551      0.465      0.477      0.265\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      29/49      2.85G    0.03343    0.02584   0.009195         46        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.581      0.486      0.503      0.292\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      30/49      2.85G    0.03329     0.0253   0.008874         36        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.542      0.479      0.466      0.273\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      31/49      2.85G    0.03306    0.02547   0.008554         40        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914       0.57      0.479      0.487      0.287\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      32/49      2.85G    0.03278    0.02541   0.008559         59        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.594      0.476      0.498      0.292\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      33/49      2.85G    0.03219    0.02537   0.008325         41        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914       0.58      0.487      0.496      0.292\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      34/49      2.85G     0.0317    0.02498   0.007901         46        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.617      0.483      0.506      0.301\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      35/49      2.85G    0.03204    0.02487   0.007678         37        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.591       0.48      0.502      0.296\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      36/49      2.85G    0.03137    0.02436   0.007344         27        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.581      0.504      0.504      0.301\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      37/49      2.85G     0.0308    0.02423   0.007531         38        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.586      0.491      0.504      0.307\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      38/49      2.85G    0.03088    0.02457   0.007376         32        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.596      0.497      0.515      0.309\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      39/49      2.85G    0.03062    0.02389   0.006846         22        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914       0.62      0.496      0.527      0.318\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      40/49      2.85G    0.02988     0.0234   0.006636         43        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.606      0.504      0.518      0.311\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      41/49      2.85G    0.02958     0.0235   0.006895         31        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.583      0.509      0.507      0.311\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      42/49      2.85G    0.02975    0.02377   0.006311         66        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.606      0.516      0.528       0.32\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      43/49      2.85G    0.02893    0.02299   0.006303         38        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.607      0.499      0.517      0.318\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      44/49      2.85G    0.02902    0.02316     0.0063         48        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914       0.62      0.502      0.531      0.333\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      45/49      2.85G    0.02851    0.02301   0.006086         58        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.628      0.498      0.529      0.327\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      46/49      2.85G    0.02811    0.02309    0.00592         43        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.656      0.491      0.532      0.328\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      47/49      2.85G      0.028    0.02257   0.005244         42        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.625      0.513      0.538      0.334\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      48/49      2.85G    0.02748    0.02268   0.005325         45        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914       0.63      0.511      0.534      0.335\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      49/49      2.85G    0.02758    0.02238    0.00554         42        640: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914       0.62      0.514      0.534      0.336\n\n50 epochs completed in 2.013 hours.\nOptimizer stripped from runs/train/Model/weights/last.pt, 14.4MB\nOptimizer stripped from runs/train/Model/weights/best.pt, 14.4MB\n\nValidating runs/train/Model/weights/best.pt...\nFusing layers... \nYOLOv5s summary: 157 layers, 7064065 parameters, 0 gradients, 15.9 GFLOPs\n                 Class     Images  Instances          P          R      mAP50   \n                   all       3425       7914      0.621      0.514      0.535      0.337\n                person       3425       3480      0.744      0.709      0.744      0.514\n                   car       3425        397      0.671      0.499      0.557      0.386\n                 chair       3425        594      0.543      0.355      0.351      0.201\n                bottle       3425        306      0.482      0.301      0.263      0.151\n           pottedplant       3425        275      0.509      0.358      0.356      0.167\n                  bird       3425        232      0.619      0.603      0.559       0.33\n                   dog       3425        310      0.723      0.556      0.612       0.41\n                  sofa       3425        168      0.542      0.393      0.455      0.284\n               bicycle       3425        197      0.664       0.32      0.403      0.239\n                 horse       3425        167      0.718      0.353      0.479      0.307\n                  boat       3425        211      0.408      0.464      0.382      0.202\n             motorbike       3425        147      0.585      0.463      0.508      0.311\n                   cat       3425        274      0.713      0.672      0.698      0.417\n             tvmonitor       3425        182      0.687      0.484      0.527      0.347\n                   cow       3425        144      0.647      0.522      0.562      0.358\n                 sheep       3425        240      0.587      0.604      0.604      0.381\n             aeroplane       3425        182      0.792      0.758      0.775       0.49\n                 train       3425        153      0.716      0.739       0.75       0.47\n           diningtable       3425        135      0.448      0.444      0.409      0.216\n                   bus       3425        120      0.615      0.692      0.701       0.55\nResults saved to \u001b[1mruns/train/Model\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!python export.py --weights /kaggle/working/yolov5/runs/train/Model/weights/best.pt --include torchscript onnx","metadata":{"execution":{"iopub.status.busy":"2024-01-10T10:03:32.758807Z","iopub.execute_input":"2024-01-10T10:03:32.759196Z","iopub.status.idle":"2024-01-10T10:03:43.141868Z","shell.execute_reply.started":"2024-01-10T10:03:32.759156Z","shell.execute_reply":"2024-01-10T10:03:43.140068Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mexport: \u001b[0mdata=data/coco128.yaml, weights=['/kaggle/working/yolov5/runs/train/Model/weights/best.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, per_tensor=False, dynamic=False, simplify=False, opset=17, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['torchscript', 'onnx']\nYOLOv5 üöÄ v7.0-270-g4733b4d Python-3.10.12 torch-2.0.0 CPU\n\nFusing layers... \nYOLOv5s summary: 157 layers, 7064065 parameters, 0 gradients, 15.9 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /kaggle/working/yolov5/runs/train/Model/weights/best.pt with output shape (1, 25200, 25) (13.8 MB)\n\n\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.0.0...\n\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ‚úÖ 2.1s, saved as /kaggle/working/yolov5/runs/train/Model/weights/best.torchscript (27.4 MB)\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0...\n================ Diagnostic Run torch.onnx.export version 2.0.0 ================\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 1.0s, saved as /kaggle/working/yolov5/runs/train/Model/weights/best.onnx (27.4 MB)\n\nExport complete (3.7s)\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/train/Model/weights\u001b[0m\nDetect:          python detect.py --weights /kaggle/working/yolov5/runs/train/Model/weights/best.onnx \nValidate:        python val.py --weights /kaggle/working/yolov5/runs/train/Model/weights/best.onnx \nPyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', '/kaggle/working/yolov5/runs/train/Model/weights/best.onnx')  \nVisualize:       https://netron.app\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive('/kaggle/working/results', 'zip', '/kaggle/working/yolov5/runs/train/Model')","metadata":{"execution":{"iopub.status.busy":"2024-01-10T10:05:16.826049Z","iopub.execute_input":"2024-01-10T10:05:16.826437Z","iopub.status.idle":"2024-01-10T10:05:21.978619Z","shell.execute_reply.started":"2024-01-10T10:05:16.826408Z","shell.execute_reply":"2024-01-10T10:05:21.977700Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/results.zip'"},"metadata":{}}]}]}